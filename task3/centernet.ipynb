{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import CocoDetection\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abbyy_course_cvdl_t3.coco_text import COCO_Text\n",
    "from abbyy_course_cvdl_t3 import coco_evaluation\n",
    "from abbyy_course_cvdl_t3.utils import evaluate_ap_from_cocotext_json\n",
    "from abbyy_course_cvdl_t3.utils import dump_detections_to_cocotext_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../task2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import abbyy_course_cvdl_t2\n",
    "from abbyy_course_cvdl_t2.convert import PointsToObjects, ObjectsToPoints\n",
    "from abbyy_course_cvdl_t2.impl.train import train\n",
    "from abbyy_course_cvdl_t2.impl.data import CocoTextDetection, CocoDetectionPrepareTransform\n",
    "from abbyy_course_cvdl_t2.network import CenterNet\n",
    "from abbyy_course_cvdl_t2.loss import CenterNetLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path(\"/home/alexander/Downloads/coco2014/\")\n",
    "anno_path = base / 'cocotext.v2.json'\n",
    "images_path = base / 'images/train2014'\n",
    "\n",
    "assert anno_path.exists(), \"Set your own path to annotation\"\n",
    "assert images_path.exists(), \"Set your own path to images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = COCO_Text(anno_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(image_np, yc_t, xc_t, hy_t, wx_t, color=(0, 255, 0), thick=1):\n",
    "    img = np.array(image_np)\n",
    "    num_boxes = len(yc_t)\n",
    "    val = np.array(color)\n",
    "    for idx in range(num_boxes):\n",
    "        yc = yc_t[idx]\n",
    "        xc = xc_t[idx]\n",
    "        hy = hy_t[idx]\n",
    "        wx = wx_t[idx]\n",
    "        img[\n",
    "                yc - hy//2 - thick : yc - hy//2 + thick, \n",
    "                xc - wx//2 : xc + wx//2, \n",
    "        ] = val\n",
    "        img[\n",
    "                yc + hy//2 - thick : yc + hy//2 + thick, \n",
    "                xc - wx//2 : xc + wx//2, \n",
    "        ] = val\n",
    "\n",
    "        img[\n",
    "                yc - hy//2 : yc + hy//2, \n",
    "                (xc - wx//2 - thick): (xc - wx//2 + thick), \n",
    "        ] = val\n",
    "        img[\n",
    "                yc - hy//2 : yc + hy//2, \n",
    "                xc + wx//2 - thick: xc + wx//2 + thick, \n",
    "        ] = val\n",
    "    return img\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2\n",
    "input_shape = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = CocoTextDetection(\n",
    "    Path(\"/home/alexander/Downloads/coco2014/images/train2014\"),\n",
    "    Path(\"/home/alexander/Downloads/coco2014/cocotext.v2.json\"),\n",
    "    transforms=CocoDetectionPrepareTransform(size=input_shape, #ids_map = {1: 0, 0: 0}\n",
    "),\n",
    "    area_fraction_threshold=1/32/32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_val = CocoTextDetection(\n",
    "    images_path,\n",
    "    Path(anno_path),\n",
    "    transforms=CocoDetectionPrepareTransform(size=input_shape, #ids_map = {1: 0, 0: 0}\n",
    "    ),\n",
    "    area_fraction_threshold=1/32/32,\n",
    "    split='val'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = ds_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd = lambda x: torch.round(x).long()\n",
    "\n",
    "plt.imshow(draw_boxes(\n",
    "    x.permute(1, 2, 0).numpy(), rnd(y[:, 0]), rnd(y[:, 1]), rnd(y[:, 2]), rnd(y[:, 3]) \n",
    "))\n",
    "#plt.imshow(x.permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(\n",
    "    ds_train, batch_size=2, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valloader = torch.utils.data.DataLoader(\n",
    "    ds_val, batch_size=1, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = CenterNet(head_kwargs={'c_classes': n_classes}, nms_kwargs={'kernel_size': 5})\n",
    "crit = CenterNetLoss(obj_to_points=ObjectsToPoints(num_classes=n_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = train(ds_train, net=net, criterion=crit, batch_size=64, epochs=120, device=torch.device(device), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net, 'centernet.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.load('centernet.pth')\n",
    "net.to(device)\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_id = 101243\n",
    "img_meta = ct.loadImgs(ids=[img_id])[0]\n",
    "plt.imshow(plt.imread(images_path / img_meta['file_name']))\n",
    "annIds = ct.getAnnIds(imgIds=img_meta['id'])\n",
    "anns = ct.loadAnns(annIds)\n",
    "ct.showAnns(anns)\n",
    "plt.title(f\"GT: {img_meta['id']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, anno = ds_val[ds_val.ids.index(str(img_id))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    preds = net(img[None, :].to(device))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(data, scale=1.):\n",
    "    unf = {}\n",
    "    res = data[data[:, :, -1] > 0.2].detach()\n",
    "    boxes = res[:, :4].clone()\n",
    "    b = boxes.clone()\n",
    "    boxes[:, 2] = (b[:, 2] - b[:, 0])\n",
    "    boxes[:, 3] = (b[:, 3] - b[:, 1])\n",
    "    boxes *= scale\n",
    "    unf['boxes'] = boxes.numpy()\n",
    "    unf['scores'] = res[:, -1].detach().numpy()\n",
    "    return unf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_preds = []\n",
    "img_ids = []\n",
    "\n",
    "net.eval()\n",
    "\n",
    "for num, img_id in enumerate(tqdm(ds_val.ids)):\n",
    "    img_id = int(img_id)\n",
    "    img_meta = ct.loadImgs(ids=[img_id])[0]\n",
    "    with torch.no_grad():\n",
    "        x = ds_val[num][0]\n",
    "        pred = net(\n",
    "            x[None, ...].to(device),\n",
    "            return_objects=True\n",
    "        )[0].detach().cpu().numpy()\n",
    "        prepared_preds.append(\n",
    "            postprocess(pred, scale=x.shape[1] / input_shape[1])\n",
    "        )\n",
    "        img_ids.append(img_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upscale maybe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prpr = []\n",
    "for i in prepared_preds:\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving to json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.concatenate([u['scores'] for u in prepared_preds], axis=0)\n",
    "boxes = np.concatenate([u['boxes'] for u in prepared_preds], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = []\n",
    "for num, i in enumerate(img_ids):\n",
    "    image_ids += [i] * len(prepared_preds[num]['boxes'])\n",
    "image_ids = np.array(image_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_ids.tolist()),\n",
    "    len(boxes[:, 0].tolist()),\n",
    "    len(boxes[:, 1].tolist()),\n",
    "    len(boxes[:, 2].tolist()),\n",
    "    len(boxes[:, 3].tolist()),\n",
    "    len(scores.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_detections_to_cocotext_json(\n",
    "    image_ids = image_ids.tolist(),\n",
    "    xlefts=boxes[:, 0].tolist(),\n",
    "    ytops=boxes[:, 1].tolist(),\n",
    "    widths=boxes[:, 2].tolist(),\n",
    "    heights=boxes[:, 3].tolist(),\n",
    "    scores=scores.tolist(),\n",
    "    path='predictions.json'\n",
    ");\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AP calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap, prec, rec = evaluate_ap_from_cocotext_json(\n",
    "    coco_text=ct,\n",
    "    path='predictions.json'\n",
    ")\n",
    "print(f\"Итоговый скор AP на val: {ap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(prec, rec)\n",
    "plt.xlabel('precision')\n",
    "plt.ylabel('recall')\n",
    "plt.title('PR curve')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9de35f58b490df70c64b1db97b3e54dc2a525ab2d36632bb7ddc91e7dd00330b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
