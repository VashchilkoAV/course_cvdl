{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/avashchilko/abbyy9sem/course_cvdl/.venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models\n",
    "import collections\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "import imagenet.mobilenet\n",
    "from torch import optim\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    # Initialize kernel weights with Gaussian distributions\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.ConvTranspose2d):\n",
    "        n = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
    "        m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.zero_()\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        m.weight.data.fill_(1)\n",
    "        m.bias.data.zero_()\n",
    "\n",
    "\n",
    "class DepthwiseConv(nn.Module):\n",
    "    def __init__(self, in_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        padding = (kernel_size-1) // 2\n",
    "        assert 2  * padding == kernel_size-1, f\"parameters incorrect. kernel={kernel_size}, padding={padding}\"\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=in_channels, \n",
    "                      kernel_size=kernel_size, padding=padding, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # add init weights\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "\n",
    "class PointwiseConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels, \n",
    "            kernel_size=1, padding=0, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        # add init weights\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class ConvDecomposed(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            DepthwiseConv(in_channels=in_channels, kernel_size=kernel_size),\n",
    "            PointwiseConv(in_channels=in_channels, out_channels=out_channels)\n",
    "        )\n",
    "        \n",
    "        # add init weights\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "        \n",
    "        \n",
    "# use this in mobilenet.py\n",
    "# replace .view() in mobilent.py\n",
    "\n",
    "class NNConv5(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, interpolation_scale_factor):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.interpolation_scale_factor = interpolation_scale_factor\n",
    "        \n",
    "        self.net = ConvDecomposed(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.net(x)\n",
    "        return F.interpolate(x, scale_factor=self.interpolation_scale_factor, mode='nearest')\n",
    "    \n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self, pretrained=True, decoder_kernel_size=5, decoder_interpolation_scale_factor=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        mobilenet = imagenet.mobilenet.MobileNet()\n",
    "        if pretrained:\n",
    "            pretrained_path = os.path.join('cifar100.pth')\n",
    "            checkpoint = torch.load(pretrained_path, map_location='cpu')\n",
    "            state_dict = checkpoint.state_dict()\n",
    "\n",
    "            from collections import OrderedDict\n",
    "            new_state_dict = OrderedDict()\n",
    "            for k, v in state_dict.items():\n",
    "                name = k[7:] # remove `module.`\n",
    "                new_state_dict[name] = v\n",
    "            #mobilenet.load_state_dict(new_state_dict)\n",
    "            mobilenet.load_state_dict(state_dict)\n",
    "        else:\n",
    "            mobilenet.apply(weights_init)\n",
    "\n",
    "        for i in range(14):\n",
    "            setattr( self, 'conv{}'.format(i), mobilenet.model[i])\n",
    "            \n",
    "        self.decode_conv1 = NNConv5(in_channels=1024, out_channels=512, \n",
    "                                    kernel_size=decoder_kernel_size,\n",
    "                                    interpolation_scale_factor=decoder_interpolation_scale_factor)\n",
    "       \n",
    "        self.decode_conv2 = NNConv5(in_channels=512, out_channels=256, \n",
    "                                    kernel_size=decoder_kernel_size,\n",
    "                                    interpolation_scale_factor=decoder_interpolation_scale_factor)\n",
    "        \n",
    "        self.decode_conv3 = NNConv5(in_channels=256, out_channels=128, \n",
    "                                    kernel_size=decoder_kernel_size,\n",
    "                                    interpolation_scale_factor=decoder_interpolation_scale_factor)\n",
    "    \n",
    "        self.decode_conv4 = NNConv5(in_channels=128, out_channels=64, \n",
    "                                    kernel_size=decoder_kernel_size,\n",
    "                                    interpolation_scale_factor=decoder_interpolation_scale_factor)\n",
    "        \n",
    "        self.decode_conv5 = NNConv5(in_channels=64, out_channels=32, \n",
    "                                    kernel_size=decoder_kernel_size,\n",
    "                                    interpolation_scale_factor=decoder_interpolation_scale_factor)\n",
    "        \n",
    "        self.decode_conv6 = PointwiseConv(in_channels=32, out_channels=1)\n",
    "        weights_init(self.decode_conv1)\n",
    "        weights_init(self.decode_conv2)\n",
    "        weights_init(self.decode_conv3)\n",
    "        weights_init(self.decode_conv4)\n",
    "        weights_init(self.decode_conv5)\n",
    "        weights_init(self.decode_conv6)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # skip connections: dec4: enc1\n",
    "        # dec 3: enc2 or enc3\n",
    "        # dec 2: enc4 or enc5\n",
    "        for i in range(14):\n",
    "            layer = getattr(self, f'conv{i}')\n",
    "            x = layer(x)\n",
    "            if i==1:\n",
    "                x1 = x\n",
    "            elif i==3:\n",
    "                x2 = x\n",
    "            elif i==5:\n",
    "                x3 = x\n",
    "        for i in range(1,6):\n",
    "            layer = getattr(self, f'decode_conv{i}')\n",
    "            x = layer(x)\n",
    "            if i==4:\n",
    "                x = x + x1\n",
    "            elif i==3:\n",
    "                x = x + x2\n",
    "            elif i==2:\n",
    "                x = x + x3\n",
    "        x = self.decode_conv6(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders.nyu import NYUDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, net=None, criterion=None, optimizer=None, batch_size=8, lr=3e-4, epochs=20, device=None):\n",
    "    log = []\n",
    "    if device is not None:\n",
    "        net.to(device)\n",
    "    \n",
    "    if optimizer is None:\n",
    "        optimizer = optim.Adam(net.parameters(), lr=lr)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
    "    )\n",
    "    \n",
    "    stats_step = (len(dataset) // 10 // batch_size) + 1\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, targets = data\n",
    "            if device is not None:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            losses = criterion(outputs, targets).mean(axis=0)\n",
    "            loss_value = losses.sum()\n",
    "            if torch.isnan(loss_value).any():\n",
    "                warnings.warn(\"nan loss! skip update\")\n",
    "                print(f\"last loss: {[l.item() for l in losses]}\")\n",
    "                break\n",
    "            running_loss += loss_value\n",
    "            if (i % stats_step == 0):\n",
    "                print(f\"epoch {epoch}|{i}; total loss:{running_loss / stats_step}\")\n",
    "                print(f\"last losses: {[l.item() for l in losses.flatten()]}\")\n",
    "                log.append([l.item() for l in losses.flatten()])\n",
    "                running_loss = 0.0\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "    print('Finished Training')\n",
    "    return net, log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "    transforms.Resize(228)])\n",
    "\n",
    "imagenet_data = torchvision.datasets.CIFAR100('/DATA/vashchilko/', train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = imagenet.mobilenet.MobileNet()\n",
    "lr = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "batch_size = 64\n",
    "epochs = 50\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_net, log = train(imagenet_data, net=net, criterion=criterion,\n",
    "                    batch_size=batch_size, lr=lr,\n",
    "                    epochs=epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_net, 'cifar100.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training on NYUv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nyu = Path(\"/DATA/vashchilko/nyudepthv2\")\n",
    "traindir_nyu = base_nyu / 'train'\n",
    "valdir_nyu = base_nyu / 'val'\n",
    "\n",
    "assert traindir_nyu.exists(), \"Set your own path to train\"\n",
    "assert valdir_nyu.exists(), \"Set your own path to val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = NYUDataset(traindir_nyu, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Model(pretrained=True)\n",
    "lr = 0.01\n",
    "optimizer = optim.SGD(net.parameters(), lr=lr, momentum=0.9, weight_decay=0.0001)\n",
    "criterion = nn.MSELoss()\n",
    "batch_size = 8\n",
    "epochs = 12\n",
    "device = torch.device('cuda:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0|0; total loss:0.007855179719626904\n",
      "last losses: [4.6188459396362305]\n",
      "epoch 0|588; total loss:1.5750302076339722\n",
      "last losses: [0.8299457430839539]\n",
      "epoch 0|1176; total loss:1.1929091215133667\n",
      "last losses: [0.6045311689376831]\n",
      "epoch 0|1764; total loss:1.1383962631225586\n",
      "last losses: [0.6842315196990967]\n",
      "epoch 0|2352; total loss:1.1238526105880737\n",
      "last losses: [0.999713659286499]\n",
      "epoch 0|2940; total loss:1.1364283561706543\n",
      "last losses: [1.2110828161239624]\n",
      "epoch 0|3528; total loss:1.1381560564041138\n",
      "last losses: [0.9315807223320007]\n",
      "epoch 0|4116; total loss:1.082692265510559\n",
      "last losses: [1.0542418956756592]\n",
      "epoch 0|4704; total loss:1.0908362865447998\n",
      "last losses: [1.9334301948547363]\n",
      "epoch 0|5292; total loss:1.0529404878616333\n",
      "last losses: [0.3099454641342163]\n",
      "epoch 1|0; total loss:0.002685386687517166\n",
      "last losses: [1.5790073871612549]\n",
      "epoch 1|588; total loss:1.037062168121338\n",
      "last losses: [1.1000579595565796]\n",
      "epoch 1|1176; total loss:1.047691822052002\n",
      "last losses: [0.6752759218215942]\n",
      "epoch 1|1764; total loss:1.0183892250061035\n",
      "last losses: [0.5446009039878845]\n",
      "epoch 1|2352; total loss:1.0037248134613037\n",
      "last losses: [0.6335813403129578]\n",
      "epoch 1|2940; total loss:1.0288505554199219\n",
      "last losses: [0.975948691368103]\n",
      "epoch 1|3528; total loss:0.9842843413352966\n",
      "last losses: [0.8610475063323975]\n",
      "epoch 1|4116; total loss:0.971412181854248\n",
      "last losses: [0.4716314375400543]\n",
      "epoch 1|4704; total loss:0.9856265187263489\n",
      "last losses: [0.7123321890830994]\n",
      "epoch 1|5292; total loss:0.971107006072998\n",
      "last losses: [0.818709671497345]\n",
      "epoch 2|0; total loss:0.0022024258505553007\n",
      "last losses: [1.295026421546936]\n",
      "epoch 2|588; total loss:0.9833774566650391\n",
      "last losses: [0.4074057638645172]\n",
      "epoch 2|1176; total loss:0.9821500778198242\n",
      "last losses: [1.6526310443878174]\n",
      "epoch 2|1764; total loss:0.956366777420044\n",
      "last losses: [2.443678855895996]\n",
      "epoch 2|2352; total loss:0.9474655389785767\n",
      "last losses: [1.0367335081100464]\n",
      "epoch 2|2940; total loss:0.9350979924201965\n",
      "last losses: [1.0456644296646118]\n",
      "epoch 2|3528; total loss:0.9028681516647339\n",
      "last losses: [0.6340152025222778]\n",
      "epoch 2|4116; total loss:0.9407662749290466\n",
      "last losses: [1.2587510347366333]\n",
      "epoch 2|4704; total loss:0.934691309928894\n",
      "last losses: [0.99718177318573]\n",
      "epoch 2|5292; total loss:0.9175765514373779\n",
      "last losses: [1.5255316495895386]\n",
      "epoch 3|0; total loss:0.0014599317219108343\n",
      "last losses: [0.8584398627281189]\n",
      "epoch 3|588; total loss:0.9447993636131287\n",
      "last losses: [1.8220542669296265]\n",
      "epoch 3|1176; total loss:0.9047214984893799\n",
      "last losses: [0.8661059737205505]\n",
      "epoch 3|1764; total loss:0.9192584753036499\n",
      "last losses: [0.5762291550636292]\n",
      "epoch 3|2352; total loss:0.9088740944862366\n",
      "last losses: [1.0077627897262573]\n",
      "epoch 3|2940; total loss:0.9172571897506714\n",
      "last losses: [1.4619066715240479]\n",
      "epoch 3|3528; total loss:0.8937845826148987\n",
      "last losses: [0.8435713052749634]\n",
      "epoch 3|4116; total loss:0.8860872983932495\n",
      "last losses: [0.7369421720504761]\n",
      "epoch 3|4704; total loss:0.9159623384475708\n",
      "last losses: [0.9129308462142944]\n",
      "epoch 3|5292; total loss:0.8873617053031921\n",
      "last losses: [0.7183586955070496]\n",
      "epoch 4|0; total loss:0.0012060962617397308\n",
      "last losses: [0.7091845870018005]\n",
      "epoch 4|588; total loss:0.8683496713638306\n",
      "last losses: [1.0817538499832153]\n",
      "epoch 4|1176; total loss:0.9154471158981323\n",
      "last losses: [0.3651459217071533]\n",
      "epoch 4|1764; total loss:0.8808507323265076\n",
      "last losses: [0.681521475315094]\n",
      "epoch 4|2352; total loss:0.8394643068313599\n",
      "last losses: [0.48511624336242676]\n",
      "epoch 4|2940; total loss:0.8807914853096008\n",
      "last losses: [0.8998889327049255]\n",
      "epoch 4|3528; total loss:0.8635732531547546\n",
      "last losses: [0.5037247538566589]\n",
      "epoch 4|4116; total loss:0.8874608874320984\n",
      "last losses: [1.1204787492752075]\n",
      "epoch 4|4704; total loss:0.8996347188949585\n",
      "last losses: [0.7843504548072815]\n",
      "epoch 4|5292; total loss:0.8795372247695923\n",
      "last losses: [1.0160493850708008]\n",
      "epoch 5|0; total loss:0.001283490564674139\n",
      "last losses: [0.7546924352645874]\n",
      "epoch 5|588; total loss:0.8465893268585205\n",
      "last losses: [1.0765771865844727]\n",
      "epoch 5|1176; total loss:0.8635997772216797\n",
      "last losses: [1.3090205192565918]\n",
      "epoch 5|1764; total loss:0.8263962268829346\n",
      "last losses: [0.8847989439964294]\n",
      "epoch 5|2352; total loss:0.8455807566642761\n",
      "last losses: [1.0594596862792969]\n",
      "epoch 5|2940; total loss:0.8344417810440063\n",
      "last losses: [0.58849036693573]\n",
      "epoch 5|3528; total loss:0.861215353012085\n",
      "last losses: [0.44868093729019165]\n",
      "epoch 5|4116; total loss:0.793739914894104\n",
      "last losses: [1.2796348333358765]\n",
      "epoch 5|4704; total loss:0.8444841504096985\n",
      "last losses: [1.8497495651245117]\n",
      "epoch 5|5292; total loss:0.826620876789093\n",
      "last losses: [0.5920136570930481]\n",
      "epoch 6|0; total loss:0.0007653647335246205\n",
      "last losses: [0.4500344693660736]\n",
      "epoch 6|588; total loss:0.8325958251953125\n",
      "last losses: [0.30092206597328186]\n",
      "epoch 6|1176; total loss:0.7721151113510132\n",
      "last losses: [0.7571357488632202]\n",
      "epoch 6|1764; total loss:0.8119986653327942\n",
      "last losses: [0.7310552000999451]\n",
      "epoch 6|2352; total loss:0.8009721040725708\n",
      "last losses: [0.43951520323753357]\n",
      "epoch 6|2940; total loss:0.7830341458320618\n",
      "last losses: [1.4110310077667236]\n",
      "epoch 6|3528; total loss:0.8042722344398499\n",
      "last losses: [1.3849060535430908]\n",
      "epoch 6|4116; total loss:0.788237988948822\n",
      "last losses: [0.6717506051063538]\n",
      "epoch 6|4704; total loss:0.7872833013534546\n",
      "last losses: [0.4888019859790802]\n",
      "epoch 6|5292; total loss:0.7757272720336914\n",
      "last losses: [0.7352593541145325]\n",
      "epoch 7|0; total loss:0.0015998338349163532\n",
      "last losses: [0.9407023191452026]\n",
      "epoch 7|588; total loss:0.8015948534011841\n",
      "last losses: [0.9346028566360474]\n",
      "epoch 7|1176; total loss:0.7625138759613037\n",
      "last losses: [1.2624200582504272]\n",
      "epoch 7|1764; total loss:0.7614687085151672\n",
      "last losses: [0.46646061539649963]\n",
      "epoch 7|2352; total loss:0.8160539269447327\n",
      "last losses: [0.37014979124069214]\n",
      "epoch 7|2940; total loss:0.7664279937744141\n",
      "last losses: [0.9344198703765869]\n",
      "epoch 7|3528; total loss:0.7808782458305359\n",
      "last losses: [0.859624445438385]\n",
      "epoch 7|4116; total loss:0.7525714039802551\n",
      "last losses: [1.5228307247161865]\n",
      "epoch 7|4704; total loss:0.7716461420059204\n",
      "last losses: [0.8654351830482483]\n",
      "epoch 7|5292; total loss:0.7393417954444885\n",
      "last losses: [0.9143316149711609]\n",
      "epoch 8|0; total loss:0.002016181591898203\n",
      "last losses: [1.1855148077011108]\n",
      "epoch 8|588; total loss:0.7515541315078735\n",
      "last losses: [1.0235636234283447]\n",
      "epoch 8|1176; total loss:0.7695918679237366\n",
      "last losses: [0.9341464638710022]\n",
      "epoch 8|1764; total loss:0.7355426549911499\n",
      "last losses: [0.26742300391197205]\n",
      "epoch 8|2352; total loss:0.7475875020027161\n",
      "last losses: [1.4113024473190308]\n",
      "epoch 8|2940; total loss:0.753838837146759\n",
      "last losses: [0.5520547032356262]\n",
      "epoch 8|3528; total loss:0.7441799640655518\n",
      "last losses: [0.8915959596633911]\n",
      "epoch 8|4116; total loss:0.7575056552886963\n",
      "last losses: [0.7961162328720093]\n",
      "epoch 8|4704; total loss:0.7451329231262207\n",
      "last losses: [0.6365190744400024]\n",
      "epoch 8|5292; total loss:0.7291185855865479\n",
      "last losses: [0.8284823298454285]\n",
      "epoch 9|0; total loss:0.0021557817235589027\n",
      "last losses: [1.2675997018814087]\n",
      "epoch 9|588; total loss:0.7533471584320068\n",
      "last losses: [1.2714303731918335]\n",
      "epoch 9|1176; total loss:0.7038443684577942\n",
      "last losses: [0.9625406861305237]\n",
      "epoch 9|1764; total loss:0.7085514664649963\n",
      "last losses: [0.8416829109191895]\n",
      "epoch 9|2352; total loss:0.7411719560623169\n",
      "last losses: [0.3987081050872803]\n",
      "epoch 9|2940; total loss:0.7324422597885132\n",
      "last losses: [0.7048593759536743]\n",
      "epoch 9|3528; total loss:0.7125558257102966\n",
      "last losses: [0.8056302666664124]\n",
      "epoch 9|4116; total loss:0.7035965323448181\n",
      "last losses: [1.495108723640442]\n",
      "epoch 9|4704; total loss:0.7104503512382507\n",
      "last losses: [1.12808096408844]\n",
      "epoch 9|5292; total loss:0.7257514595985413\n",
      "last losses: [1.04554283618927]\n",
      "epoch 10|0; total loss:0.0012326953001320362\n",
      "last losses: [0.724824845790863]\n",
      "epoch 10|588; total loss:0.7072961330413818\n",
      "last losses: [0.7535573840141296]\n",
      "epoch 10|1176; total loss:0.7183395028114319\n",
      "last losses: [0.42671170830726624]\n",
      "epoch 10|1764; total loss:0.7101050019264221\n",
      "last losses: [0.38680168986320496]\n",
      "epoch 10|2352; total loss:0.6620558500289917\n",
      "last losses: [1.9285372495651245]\n",
      "epoch 10|2940; total loss:0.7155073285102844\n",
      "last losses: [0.6903336644172668]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10|3528; total loss:0.7228920459747314\n",
      "last losses: [0.5855341553688049]\n",
      "epoch 10|4116; total loss:0.7226430773735046\n",
      "last losses: [0.3254247307777405]\n",
      "epoch 10|4704; total loss:0.7037139534950256\n",
      "last losses: [0.6441723704338074]\n",
      "epoch 10|5292; total loss:0.688650906085968\n",
      "last losses: [0.648614227771759]\n",
      "epoch 11|0; total loss:0.0006703315884806216\n",
      "last losses: [0.39415499567985535]\n",
      "epoch 11|588; total loss:0.6803773641586304\n",
      "last losses: [1.0145773887634277]\n",
      "epoch 11|1176; total loss:0.686488926410675\n",
      "last losses: [0.7559367418289185]\n",
      "epoch 11|1764; total loss:0.6973398923873901\n",
      "last losses: [0.3075387179851532]\n",
      "epoch 11|2352; total loss:0.6868622303009033\n",
      "last losses: [0.27569329738616943]\n",
      "epoch 11|2940; total loss:0.7018951177597046\n",
      "last losses: [0.48289287090301514]\n",
      "epoch 11|3528; total loss:0.6761839985847473\n",
      "last losses: [0.33826375007629395]\n",
      "epoch 11|4116; total loss:0.6826497316360474\n",
      "last losses: [0.3034030795097351]\n",
      "epoch 11|4704; total loss:0.6746731400489807\n",
      "last losses: [0.979778528213501]\n",
      "epoch 11|5292; total loss:0.6936527490615845\n",
      "last losses: [0.6737775802612305]\n",
      "Finished Training\n",
      "CPU times: user 1h 8min 30s, sys: 3min 40s, total: 1h 12min 11s\n",
      "Wall time: 4h 4min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trained_net, log = train(train_dataset, net=net, criterion=criterion,\n",
    "                    batch_size=batch_size, lr=lr,\n",
    "                    epochs=epochs, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_net, 'trained1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(trained_net.state_dict(), 'trained1_state.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
